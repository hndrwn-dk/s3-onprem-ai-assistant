# ğŸ§  S3 On-Prem AI Assistant

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/LangChain-0.2%2B-green.svg)](https://python.langchain.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-App-red)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Offline AI](https://img.shields.io/badge/Offline-AI-important.svg)](https://ollama.com/)
[![Mistral Powered](https://img.shields.io/badge/LLM-Mistral_7B-ff69b4.svg)](https://ollama.com/library/mistral)

A fully offline-capable AI assistant for answering operational, admin, and troubleshooting questions for on-premises S3-compatible platforms such as:

- ğŸ“¦ Cloudian HyperStore
- ğŸ§Š Huawei OceanStor
- âš¡ Pure FlashBlade
- ğŸ¢ IBM Cloud Object Storage
- ğŸ³ MinIO and more

## Supports

- âš¡ Hybrid vector + structured fallback
- ğŸ§¾ JSON-based metadata lookups
- ğŸŒ Streamlit UI and FastAPI endpoint
- ğŸ§  Mistral 7B running via Ollama (no API key needed)

---

## ğŸ“ Folder Structure

```bash
s3_onprem_ai_assistant/
â”œâ”€â”€ api.py                  # FastAPI REST API
â”œâ”€â”€ build_embeddings_all.py # Unified embedding + conversion
â”œâ”€â”€ config.py               # Central settings and paths
â”œâ”€â”€ s3ai_query.py           # CLI query tool
â”œâ”€â”€ streamlit_ui.py         # Streamlit web UI
â”œâ”€â”€ utils.py                # Utility + fallback handler
â”œâ”€â”€ docs/                   # Place .pdf / .md / .json here
â”‚   â”œâ”€â”€ *.pdf               # Admin guides
â”‚   â”œâ”€â”€ *.json              # Metadata
â”‚   â””â”€â”€ *.txt / *.md        # Optional raw or converted text
```

---

## ğŸ§° Requirements

- Python 3.12+
- Ollama + Mistral 7B

### 1ï¸âƒ£ Install Python dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Install Ollama + Mistral

```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama run mistral
```

---

## ğŸš€ Quickstart

### 1. ğŸ—‚ Prepare your files in docs/

Drop any combination of .pdf, .md, .json, or .txt.

### 2. ğŸ§  Build or rebuild the index

```bash
python build_embeddings_all.py
```

âœ… Auto-converts .pdf, .md, .json to .txt
ğŸ§ª Use --dry-run for test mode
ğŸ“Š Prints loaded document summary

### 3. ğŸ” Query using CLI

```bash
python s3ai_query.py "What's bucket name for Finance Dept?"
```

### 4. ğŸŒ Launch the Streamlit UI

```bash
streamlit run streamlit_ui.py
```
### 5. ğŸ”Œ Call the API

```bash
uvicorn api:app --reload --port 8000
```
Access: http://localhost:8000/docs

## ğŸ§  Answering Logic
âœ… Vector search â€“ top-k content from .pdf/.md/.txt
ğŸ“„ JSON lookup fallback â€“ if vector is low-score
ğŸ“‚ TXT fallback â€“ shows matching lines from .txt docs (tagged as [TXT Fallback Matches])

## ğŸ’¬ Example Queries

| Type               | Example                                                                  |
| ------------------ | ------------------------------------------------------------------------ |
| ğŸ”§ Troubleshooting | â€œWhat does error code 403 in Huawei OBS?â€                                |
| ğŸ“Š Metadata Lookup | â€œShow requestor\_email for Bucket-001â€                                   |
| ğŸ›  Admin Tasks     | â€œHow to purge a versioned bucket in Cloudian?â€                           |
| ğŸ§¾ Lookup          | â€œFind bucket\_name with [alert1@support.com](mailto:alert1@support.com)â€ |

## ğŸ§¾ Postman Collection

```json
{
  "info": {
    "name": "S3 On-Prem AI Assistant",
    "_postman_id": "abcd1234-5678-9012-efgh-34567890ijkl",
    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
  },
  "item": [
    {
      "name": "Ask AI",
      "request": {
        "method": "POST",
        "header": [{"key": "Content-Type", "value": "application/json"}],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"query\": \"pc code 619X\"\n}"
        },
        "url": {
          "raw": "http://localhost:8000/query",
          "protocol": "http",
          "host": ["localhost"],
          "port": "8000",
          "path": ["query"]
        }
      },
      "response": []
    }
  ]
}
```

## ğŸ–¼ Streamlit Dashboard Preview

Example dashboard layout after launching streamlit_ui.py
- Place `.txt`, `.pdf`, `.md`, and `.json` files into the `docs/` folder.
- Use `flatten_json_to_txt.py` to flatten bucket metadata.

## Feature Highlights

âœ… Offline Mode (no cloud dependency)
âœ… Auto .pdf/.json/.md to .txt conversion
âœ… FAISS + HuggingFace embeddings
âœ… LLM powered by Mistral 7B
âœ… Vector + Metadata fallback
âœ… Central config/logging (via config.py)
âœ… API + CLI + Web UI
âœ… Clear history button + copy result


## ğŸ§ª Tested On

- Python 3.12
- LangChain 0.2+
- Streamlit 1.35+
- FAISS CPU 1.7.4
- Ollama (Mistral 7B)

## ğŸ“˜ License

This project is licensed under the MIT License

## ğŸ™‹â€â™‚ï¸ Contributions

Feel free to fork and enhance â€” especially to add support for other vendors (e.g. NetApp, Dell ECS). PRs welcome!
